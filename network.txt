library(Hmisc)  genus <- read.delim('CCJ.txt', row.name = 1, check.names = FALSE)  
genus1 <- genus genus1[genus1>0] <- 1 
genus <- genus[which(rowSums(genus1) >= 3), ]     
 genus_corr <- rcorr(t(genus), type = 'pearson')  
r <- genus_corr$r 
r[abs(r) < 0.7] <- 0  
p <- genus_corr$P
 p <- p.adjust(p, method = 'BH') 
  p[p>=0.05] <- -1
 p[p<0.05 & p>=0] <- 1 
p[p==-1] <- 0 
 z <- r * p diag(z) <- 0 
  head(z)[1:6,1:6]  
 
library(igraph) 
 g <- graph.adjacency(z, weighted = TRUE, mode = 'undirected') 
 g <- simplify(g)  
g <- delete.vertices(g, names(degree(g)[degree(g) == 0]))
  E(g)$correlation <- E(g)$weight
 E(g)$weight <- abs(E(g)$weight)
  adj_matrix <- as.matrix(get.adjacency(g, attr = 'correlation'))
 write.table(data.frame(adj_matrix, check.names = FALSE), 'network.adj_matrix.txt', col.names = NA, sep = '\t', quote = FALSE) 
library(igraph)  
adjacency_weight <- read.delim('network.adj_matrix.txt', row.names = 1, sep = '\t', check.names = FALSE) 
head(adjacency_weight)[1:6]    #邻接矩阵类型的网络文件 
  igraph = graph_from_adjacency_matrix(as.matrix(adjacency_weight), mode = 'undirected', weighted = TRUE, diag = FALSE) igraph    #igraph 的邻接列表 
 E(igraph)$corr <- E(igraph)$weight 
E(igraph)$weight <- abs(E(igraph)$weight) 
ecount(igraph)  
E(igraph)$weight edge <- data.frame(as_edgelist(igraph))  
   edge_list <- data.frame(   source = edge[[1]],   target = edge[[2]],   weight = E(igraph)$weight,   correlation = E(igraph)$corr,   betweenness_centrality = E(igraph)$betweenness_centrality )
 head(edge_list)
 write.table(edge_list, 'edge_list.txt', sep = '\t', row.names = FALSE, quote = FALSE)   
nodes_num <- length(V(igraph))
 nodes_num 
 edges_num <- length(E(igraph))
 edges_num 
average_degree <- mean(degree(igraph)) 
 
nodes_connectivity <- vertex.connectivity(igraph)
 nodes_connectivity 
 edges_connectivity <- edge.connectivity(igraph)
 edges_connectivity  
 average_path_length <- average.path.length(igraph, directed = FALSE
 graph_diameter <- diameter(igraph, directed = FALSE) 
 graph_density <- graph.density(igraph) 
clustering_coefficient <- transitivity(igraph) 
 betweenness_centralization <- centralization.betweenness(igraph)$centralization 
degree_centralization <- centralization.degree(igraph)$centralization 
 fc <- cluster_fast_greedy(igraph) 
modularity <- modularity(igraph, membership(fc))   
igraph_character <- data.frame(   nodes_num,    #节点数量（number of nodes）   edges_num,    #边数量（number of edges）   average_degree,    #平均度（average degree)   nodes_connectivity,    #节点连通度（vertex connectivity）   edges_connectivity,    #边连通度（edges connectivity）   average_path_length,    #平均路径长度（average path length）   graph_diameter,    #网络直径（diameter）   graph_density,    #图密度（density）   clustering_coefficient,    #聚类系数（clustering coefficient）   betweenness_centralization,    #介数中心性（betweenness centralization)   degree_centralization,    #度中心性   modularity    #模块性（modularity） ) igraph_character  
write.table(igraph_character, 'igraph_character.txt', sep = '\t', row.names = FALSE, quote = FALSE) 



关键菌种
library(igraph) adjacency_unweight <- read.delim('un.txt', row.names = 1, sep = '\t', check.names = FALSE) head(adjacency_unweight)[1:6]      igraph <- graph_from_adjacency_matrix(as.matrix(adjacency_unweight), mode = 'undirected', weighted = NULL, diag = FALSE) igraph    #igraph 的邻接列表  V(igraph)$degree <- degree(igraph)  set.seed(123) V(igraph)$modularity <- membership(cluster_fast_greedy(igraph))  nodes_list <- data.frame(   nodes_id = V(igraph)$name,    degree = V(igraph)$degree,    modularity = V(igraph)$modularity ) head(nodes_list)     write.table(nodes_list, 'nodes_list4.txt', sep = '\t', row.names = FALSE, quote = FALSE) nodes_list <- read.delim('nodes_list4.txt', row.names = 1, sep = '\t', check.names = FALSE) source('zi_pi.r') nodes_list <- nodes_list[rownames(adjacency_unweight), ]  zi_pi <- zi.pi(nodes_list, adjacency_unweight, degree = 'degree', modularity_class = 'modularity') head(zi_pi)  write.table(zi_pi, 'zi_pi_result4.txt', sep = '\t', row.names = FALSE, quote = FALSE) library(ggplot2)  zi_pi <- na.omit(zi_pi)   
zi_pi[which(zi_pi$within_module_connectivities < 2.5 & zi_pi$among_module_connectivities < 0.62),'type'] <- 'Peripherals' zi_pi[which(zi_pi$within_module_connectivities < 2.5 & zi_pi$among_module_connectivities > 0.62),'type'] <- 'Connectors' zi_pi[which(zi_pi$within_module_connectivities > 2.5 & zi_pi$among_module_connectivities < 0.62),'type'] <- 'Module hubs' zi_pi[which(zi_pi$within_module_connectivities > 2.5 & zi_pi$among_module_connectivities > 0.62),'type'] <- 'Network hubs'  ggplot(zi_pi, aes(among_module_connectivities, within_module_connectivities)) +   geom_point(aes(color = type), alpha = 0.5, size = 2) +   scale_color_manual(values = c('gray','red','blue','purple'),                      limits = c('Peripherals', 'Connectors', 'Module hubs', 'Network hubs'))+   theme(panel.grid = element_blank(), axis.line = element_line(colour = 'black'),         panel.background = element_blank(), legend.key = element_blank()) +   labs(x = 'Among-module connectivities', y = 'Within-module connectivities', color = '') +   geom_vline(xintercept = 0.62) +   geom_hline(yintercept = 2.5) 

易损性 ##' @name Information Centrality Functions ##' @rdname info.centrality ##' ##' @title Extensions to iGraph for Information Centrality ##' ##' @description Functions to compute the information centrality of a vertex (node) and network respectively. Includes a network efficiency measure to compute as a metric for information centrality. Uses graphs functions as an extension of \code{\link[igraph]{igraph}}. ##' ##' @param graph An \code{\link[igraph]{igraph}} object. May be directed or weighted as long as a shortest path can be computed. ##' @param verbose Logical. Whether computing information centrality of each node prints to monitor progress of a potentially long run-time. Defaults to FALSE. ##' @param net Numeric. Efficiency of the Network without any nodes removed. Defaults to computing for Graph given as input, can be given as a numeric if computed in advance to save run time. ##' @keywords graph network igraph centrality ##' @import igraph NULL  ##' @rdname info.centrality ##' @examples ##' ##' #generate example graphs ##' library("igraph") ##' g1 <- make_ring(10) ##' g2 <- make_star(10) ##' ##' #show network paths ##' distances(g1) ##' shortest_paths(g1, 5) ##' ##' #compute efficiency of full graphs ##' network.efficiency(g1) ##' network.efficiency(g2) ##' @export network.efficiency <- function(graph){   if(is_igraph(graph)==F) warning("Please use a valid iGraph object")   dd <- 1/shortest.paths(graph)   diag(dd) <- NA   efficiency <- mean(dd, na.rm=T)   #denom <- nrow(dd)*(ncol(dd)-1)   #sum(dd, na.rm=T)/denom   return(efficiency) }  ##' @rdname info.centrality ##' @examples ##' ##' #compute information centrality (relative efficency when removed) for each node ##' info.centrality.vertex(g1) ##' info.centrality.vertex(g2) ##' @export info.centrality.vertex <- function(graph, net=NULL, verbose=F){   if(is_igraph(graph)==F) warning("Please use a valid iGraph object")   if(is.null(net)) net <- network.efficiency(graph)   if(is.numeric(net)==F){     warning("Please ensure net is a scalar numeric")     net <- network.efficiency(graph)   }   count <- c()   for(i in 1:length(V(graph))){     count <- c(count, (net-network.efficiency(delete.vertices(graph, i)))/net)     if(verbose){       print(paste("node",i,"current\ info\ score", count[i], collapse="\t"))     }   }   return(count) } ##' @rdname info.centrality ##' @examples ##' ##' #compute total information centrality for a network ##' info.centrality.network(g1) ##' info.centrality.network(g2) ##' @export info.centrality.network <- function(graph, net=network.efficiency(graph), verbose=F) sum(info.centrality.vertex(graph))  # remove isolated nodes iso_node_id = which(degree(g)==0) g2 = delete.vertices(g, iso_node_id) # graph without isolated nodes  #check node number and links length(V(g2));length(E(g2))     # calculate vulnerability of each node node.vul<-info.centrality.vertex(g2) max(node.vul)  # remove isolated nodes iso_node_id = which(degree(igraph)==0) g2 = delete.vertices(igraph, iso_node_id) # graph without isolated nodes  #check node number and links length(V(g2));length(E(g2))     # calculate vulnerability of each node node.vul<-info.centrality.vertex(g2) max(node.vul)   正负内聚力

genus <- read.csv('CCJ.csv', row.name = 1, check.names = FALSE)
genus1 <- genus
genus1[genus1>0] <- 1
genus <- genus[which(rowSums(genus1) >= X), ]   
genus<- t(genus)
genus <- scale(genus)
cor_pearson <- cor(genus, method = 'pearson')
cor_pearson
write.table(cor_pearson, 'cor_pearson3.txt', sep = '\t', col.names = NA, quote = FALSE)
zero <- function(vec){
  num.zero <- length(which(vec == 0))
  return(num.zero)
}

#create function that averages only negative values in a vector
neg.mean <- function(vector){
  neg.vals <- vector[which(vector < 0)]
  n.mean <- mean(neg.vals)
  if(length(neg.vals) == 0) n.mean <- 0
  return(n.mean)
}

#create function that averages only positive values in a vector
pos.mean <- function(vector){
  pos.vals <- vector[which(vector > 0)]
  p.mean <- mean(pos.vals)
  if(length(pos.vals) == 0) p.mean <- 0
  return(p.mean)
}


pers.cutoff <- 0.10
## Decide the number of iterations to run for each taxon. (>= 200 is recommended)
# Larger values of iter mean the script takes longer to run
iter <- 200
## Decide whether to use taxon/column shuffle (tax.shuffle = T) or row shuffle algorithm (tax.shuffle = F)
tax.shuffle <- F
## Option to input your own correlation table
# Note that your correlation table MUST have the same number of taxa as the abundance table. There should be no empty (all zero) taxon vectors in the abundance table. 
# Even if you input your own correlation table, the persistence cutoff will be applied
use.custom.cors <- T





b<-genus
# Read in custom correlation matrix, if desired. Must set "use.custom.cors" to TRUE
if(use.custom.cors == T) {
custom.cor.mat <- read.csv("cor.csv", header = T, row.names = 1)
custom.cor.mat <- as.matrix(custom.cor.mat)
#Check that correlation matrix and abundance matrix have the same dimension
print(dim(b)[2] == dim(custom.cor.mat)[2])
}
# Suggested steps to re-format data. At the end of these steps, the data should be in a matrix "c" where there are no empty samples or blank taxon columns.
c <- as.matrix(b)
c <- c[rowSums(c) > 0, colSums(c) > 0]
# Save total number of individuals in each sample in the original matrix. This will be 1 if data are in relative abundance, but not if matrix c is count data
rowsums.orig <- rowSums(c)
# Based on persistence cutoff, define a cutoff for the number of zeroes allowed in a taxon's distribution
zero.cutoff <- ceiling(pers.cutoff * dim(c)[1])
# Remove taxa that are below the persistence cutoff
d <- c[ , apply(c, 2, zero) < (dim(c)[1]-zero.cutoff) ]
# Remove any samples that no longer have any individuals, due to removing taxa
d <- d[rowSums(d) > 0, ]
#If using custom correlation matrix, need to remove rows/columns corresponding to the taxa below persistence cutoff
if(use.custom.cors == T){
custom.cor.mat.sub <- custom.cor.mat[apply(c, 2, zero) < (dim(c)[1]-zero.cutoff), apply(c, 2, zero) < (dim(c)[1]-zero.cutoff)]
}
# Create relative abundance matrix.
rel.d <- d / rowsums.orig
# Optionally, check to see what proportion of the community is retained after cutting out taxa
hist(rowSums(rel.d))
# Create observed correlation matrix
cor.mat.true <- cor(rel.d)
# Create vector to hold median otu-otu correlations for initial otu
med.tax.cors <- vector()
# Save observed minus expected correlations. Use custom correlations if use.custom.cors = TRUE
ifelse(use.custom.cors == T, {
obs.exp.cors.mat <- custom.cor.mat.sub}, {
obs.exp.cors.mat <- cor.mat.true - med.tax.cors
}
)
diag(obs.exp.cors.mat) <- 0
# Calculate connectedness by averaging positive and negative observed - expected correlations
connectedness.pos <- apply(obs.exp.cors.mat, 2, pos.mean)
connectedness.neg <- apply(obs.exp.cors.mat, 2, neg.mean)
# Calculate cohesion by multiplying the relative abundance dataset by associated connectedness
cohesion.pos <- rel.d %*% connectedness.pos
cohesion.neg <- rel.d %*% connectedness.neg
####
#### Combine vectors into one list and print
output <- list(connectedness.neg, connectedness.pos, cohesion.neg, cohesion.pos)
names(output) <- c("Negative Connectedness", "Positive Connectedness", "Negative Cohesion", "Positive Cohesion")
print(output)
write.table(output, 'output.txt', col.names = NA, sep = '\t', quote = FALSE)
write.table(output, 'output.txt')
View(output)
write.table(output$`Negative Cohesion`, 'Negativeoutput.txt')
write.table(output$`Positive Cohesion`, 'Positiveoutput.txt')
write.table(output$`Negative Connectedness`, 'Negative Connectedness.txt')
write.table(output$`Positive Connectedness`, 'Positive Connectedness.txt')

